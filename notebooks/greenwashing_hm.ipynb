{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "127"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "from time import sleep\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "options = Options()\n",
    "options.headless = True\n",
    "driver = webdriver.Firefox(options=options)\n",
    "\n",
    "url = \"https://www2.hm.com/en_us/men/concepts/conscious-sustainable-style.html\"\n",
    "\n",
    "driver.get(url)\n",
    "sleep(3)\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        driver.find_element_by_class_name(\"js-load-more\").click()\n",
    "        sleep(3)\n",
    "    except:\n",
    "        break\n",
    "\n",
    "driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "soup = BeautifulSoup(driver.page_source,'html.parser')\n",
    "\n",
    "links = []\n",
    "\n",
    "for product in soup.find_all(class_=\"item-link\"):\n",
    "    links.append(product['href'])\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "len(links)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "1060"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://www2.hm.com/en_us/women/concepts/conscious-sustainable-style.html\"\n",
    "\n",
    "driver = webdriver.Firefox(options=options)\n",
    "\n",
    "driver.get(url)\n",
    "sleep(3)\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        driver.find_element_by_class_name(\"js-load-more\").click()\n",
    "        sleep(3)\n",
    "    except:\n",
    "        break\n",
    "\n",
    "driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "soup = BeautifulSoup(driver.page_source,'html.parser')\n",
    "\n",
    "for product in soup.find_all(class_=\"item-link\"):\n",
    "    links.append(product['href'])\n",
    "\n",
    "driver.quit()\n",
    "len(links)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1060 items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting to avoid throttling\n",
    "links1 = links[0:530]\n",
    "links2 = links[530:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slice - 530 Current progress: 100.0 %\n",
      "1019\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from IPython.display import clear_output\n",
    "\n",
    "sleepTimes = [2.1, 2.8, 3.2]\n",
    "\n",
    "info_text = []\n",
    "\n",
    "def get_info(link_list):\n",
    "    driver = webdriver.Firefox(options=options)\n",
    "\n",
    "    for link in link_list:\n",
    "        clear_output(wait=True)\n",
    "        driver.get(\"https://www2.hm.com\" + link)\n",
    "        # some don't have product info    \n",
    "        try:    \n",
    "            element = WebDriverWait(driver, 10).until(EC.presence_of_element_located((By.CLASS_NAME, \"js-open-sustainability\")))\n",
    "            driver.find_element_by_class_name(\"js-open-sustainability\").click()\n",
    "        except:\n",
    "            continue\n",
    "        soup = BeautifulSoup(driver.page_source,'html.parser')\n",
    "\n",
    "        # pieces are separate li, so add to a list, join into one item, then append that list to keep one product per item in info_text\n",
    "        li_list = []\n",
    "        for li in soup.select('ul.ProductBackground-module--sustainabilityList__15IkU > li'):\n",
    "            if \"%\" in li.text:\n",
    "                li_list.append(li.text)\n",
    "            else:\n",
    "                continue\n",
    "        \n",
    "        li_list_join = \" \".join(li_list)\n",
    "        info_text.append(li_list_join)\n",
    "        \n",
    "        print(\"slice -\", links.index(link_list[0]), \"Current progress:\", round( ( (link_list.index(link) + 1) / len(link_list) )*100, 2 ), \"%\")\n",
    "        sleep(random.choice(sleepTimes))\n",
    "    \n",
    "    driver.quit()\n",
    "\n",
    "get_info(links1)\n",
    "sleep(300)\n",
    "get_info(links2)\n",
    "\n",
    "print(len(info_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "info from 1019 products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "materials_hm = pd.Series(info_text)\n",
    "materials_hm.to_csv(\"materials_hm.csv\") "
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "34810e3b8abeb1571717c8f8919795229980cb2ee192c7ee2ae46aa006f2e2cf"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('greenwashing-HaCD2V1s': venv)",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}